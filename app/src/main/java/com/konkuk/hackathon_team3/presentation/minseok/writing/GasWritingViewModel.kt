package com.konkuk.hackathon_team3.presentation.minseok.writing

import android.Manifest
import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.net.Uri
import android.util.Log
import androidx.annotation.RequiresPermission
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.konkuk.hackathon_team3.data.service.ClovaServicePool
import com.konkuk.hackathon_team3.data.service.ServicePool
import com.konkuk.hackathon_team3.presentation.util.showCustomToast
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.delay
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import okhttp3.MediaType.Companion.toMediaTypeOrNull
import okhttp3.MultipartBody
import okhttp3.RequestBody.Companion.toRequestBody
import java.io.ByteArrayOutputStream
import java.io.File
import java.io.FileOutputStream
import java.io.IOException
import java.text.SimpleDateFormat
import java.util.Date
import java.util.Locale
import kotlin.math.abs

data class GasWritingUiState(
    // ê²Œì‹œë¬¼ ê´€ë ¨
    val imageUri: Uri? = null,
    val textContent: String = "",

    // ì‹¤ì‹œê°„ STT ê´€ë ¨
    val isRecording: Boolean = false,
    val hasAudioPermission: Boolean = false,
    val hasCameraPermission: Boolean = false,
    val isProcessingSTT: Boolean = false,
    val sttError: String? = null,
    val sttDebugInfo: String = "", // ë””ë²„ê¹… ì •ë³´ ì¶”ê°€

    val isLoading : Boolean = false
)

class GasWritingViewModel : ViewModel() {
    private val uploadService by lazy { ServicePool.uploadService }

    private val _uiState = MutableStateFlow(GasWritingUiState())
    val uiState: StateFlow<GasWritingUiState> = _uiState.asStateFlow()

    // ğŸ¯ ê°œì„ ëœ ê³ ì • ê°’ë“¤
    companion object{
        private const val CLIENT_ID = "fsg56x4fn7"
        private const val CLIENT_SECRET = "ng7hVU1DwYZ7CwM2TfjAej8nfmyGzkbq0DX6TpE8"
        private const val LANGUAGE = "Kor"

        // ì²­í¬ ì‹œê°„ì„ 2ì´ˆë¡œ ì¦ê°€ (ë” ì •í™•í•œ ì¸ì‹)
        private const val CHUNK_DURATION_MS = 2000L

        // ì²˜ë¦¬ ë”œë ˆì´ ê°ì†Œë¡œ ë” ë¹ ë¥¸ ë°˜ì‘
        private const val PROCESSING_DELAY_MS = 10L

        // VAD(Voice Activity Detection)ë¥¼ ìœ„í•œ ì„ê³„ê°’
        private const val VOICE_THRESHOLD = 500.0
        private const val SILENCE_THRESHOLD_MS = 1500L // 1.5ì´ˆ ì¹¨ë¬µ í›„ ì²˜ë¦¬

        // ë²„í¼ ë°°ìˆ˜ ì¦ê°€
        private const val BUFFER_SIZE_MULTIPLIER = 4
    }

    // ì‹¤ì‹œê°„ STTìš©
    private var audioRecord: AudioRecord? = null
    private var recordingJob: Job? = null

    // VADë¥¼ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€
    private var lastVoiceDetectedTime = 0L
    private var currentSilenceDuration = 0L

    // ì˜¤ë””ì˜¤ ì„¤ì • (ê°œì„ )
    private val sampleRate = 16000
    private val channelConfig = AudioFormat.CHANNEL_IN_MONO
    private val audioFormat = AudioFormat.ENCODING_PCM_16BIT
    // ë²„í¼ í¬ê¸° 4ë°°ë¡œ ì¦ê°€
    private val bufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat) * BUFFER_SIZE_MULTIPLIER

    private val clovaSpeechApi = ClovaServicePool.clovaSpeechService

    // ê¶Œí•œ ê´€ë¦¬
    fun updateAudioPermission(hasPermission: Boolean) {
        _uiState.value = _uiState.value.copy(hasAudioPermission = hasPermission)
    }

    fun updateCameraPermission(hasPermission: Boolean) {
        _uiState.value = _uiState.value.copy(hasCameraPermission = hasPermission)
    }

    // ì´ë¯¸ì§€ ì„¤ì •
    fun setImageUri(uri: Uri?) {
        _uiState.value = _uiState.value.copy(imageUri = uri)
    }

    // í…ìŠ¤íŠ¸ ìˆ˜ì • (TextFieldìš©)
    fun updateTextContent(text: String) {
        _uiState.value = _uiState.value.copy(textContent = text)
    }


    // ğŸ¯ ì‹¤ì‹œê°„ STT í† ê¸€
    @RequiresPermission(Manifest.permission.RECORD_AUDIO)
    fun toggleRecording(context: Context) {
        if (_uiState.value.isRecording) {
            stopRealTimeSTT()
        } else {
            startRealTimeSTT(context)
        }
    }

    @RequiresPermission(Manifest.permission.RECORD_AUDIO)
    private fun startRealTimeSTT(context: Context) {
        if (!_uiState.value.hasAudioPermission) {
            _uiState.value = _uiState.value.copy(sttError = "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤")
            return
        }

        try {
            audioRecord = AudioRecord(
                MediaRecorder.AudioSource.MIC,
                sampleRate,
                channelConfig,
                audioFormat,
                bufferSize
            )

            if (audioRecord?.state == AudioRecord.STATE_INITIALIZED) {
                audioRecord?.startRecording()

                _uiState.value = _uiState.value.copy(
                    isRecording = true,
                    sttError = null,
                    sttDebugInfo = "ë…¹ìŒ ì‹œì‘ - ë²„í¼í¬ê¸°: $bufferSize"
                )

                startRealTimeProcessing(context)
                Log.d("GasWritingViewModel", "ì‹¤ì‹œê°„ STT ì‹œì‘ - ë²„í¼í¬ê¸°: $bufferSize")
            } else {
                throw IllegalStateException("AudioRecord ì´ˆê¸°í™” ì‹¤íŒ¨")
            }
        } catch (e: Exception) {
            Log.e("GasWritingViewModel", "ì‹¤ì‹œê°„ STT ì‹œì‘ ì‹¤íŒ¨", e)
            _uiState.value = _uiState.value.copy(
                sttError = "ì‹¤ì‹œê°„ STT ì‹œì‘ ì‹¤íŒ¨: ${e.message}",
                sttDebugInfo = "ì˜¤ë¥˜: ${e.message}"
            )
        }
    }

    private fun startRealTimeProcessing(context: Context) {
        recordingJob = viewModelScope.launch(Dispatchers.IO) {
            // ë” ì •í™•í•œ ë²„í¼ í¬ê¸° ê³„ì‚°
            val samplesPerChunk = (sampleRate * CHUNK_DURATION_MS / 1000).toInt()
            val audioBuffer = ShortArray(samplesPerChunk)
            val audioChunks = mutableListOf<ByteArray>()

            var lastProcessTime = System.currentTimeMillis()
            var totalAudioProcessed = 0L
            var chunkCount = 0

            Log.d("GasWritingViewModel", "ì²­í¬ë‹¹ ìƒ˜í”Œ ìˆ˜: $samplesPerChunk")

            while (_uiState.value.isRecording &&
                audioRecord?.recordingState == AudioRecord.RECORDSTATE_RECORDING) {

                try {
                    // ì˜¤ë””ì˜¤ ë°ì´í„° ì½ê¸°
                    val shortsRead = audioRecord?.read(audioBuffer, 0, audioBuffer.size) ?: 0

                    if (shortsRead > 0) {
                        // ShortArrayë¥¼ ByteArrayë¡œ ë³€í™˜ (Little Endian)
                        val byteArray = ByteArray(shortsRead * 2)
                        for (i in 0 until shortsRead) {
                            val shortValue = audioBuffer[i]
                            byteArray[i * 2] = (shortValue.toInt() and 0xFF).toByte()
                            byteArray[i * 2 + 1] = ((shortValue.toInt() shr 8) and 0xFF).toByte()
                        }

                        // VAD - ìŒì„± í™œë™ ê°ì§€
                        val hasVoice = isVoicePresent(audioBuffer.sliceArray(0 until shortsRead))

                        if (hasVoice) {
                            lastVoiceDetectedTime = System.currentTimeMillis()
                            currentSilenceDuration = 0
                            audioChunks.add(byteArray)

                            Log.d("GasWritingViewModel", "ìŒì„± ê°ì§€ë¨ - ì§„í­ ì„ê³„ê°’ ì´ˆê³¼")
                        } else {
                            currentSilenceDuration = System.currentTimeMillis() - lastVoiceDetectedTime

                            // ì¹¨ë¬µì´ ìˆì–´ë„ ì¼ì • ì‹œê°„ê¹Œì§€ëŠ” ë²„í¼ì— ì¶”ê°€
                            if (currentSilenceDuration < SILENCE_THRESHOLD_MS && audioChunks.isNotEmpty()) {
                                audioChunks.add(byteArray)
                            }
                        }

                        val currentTime = System.currentTimeMillis()
                        val shouldProcess = (currentTime - lastProcessTime >= CHUNK_DURATION_MS && audioChunks.isNotEmpty()) ||
                                (currentSilenceDuration >= SILENCE_THRESHOLD_MS && audioChunks.isNotEmpty())

                        if (shouldProcess) {
                            chunkCount++
                            val audioDataSize = audioChunks.sumOf { it.size }
                            val durationSeconds = audioDataSize.toFloat() / (sampleRate * 2)

                            Log.d("GasWritingViewModel", "ì²­í¬ #$chunkCount ì²˜ë¦¬ ì‹œì‘ - í¬ê¸°: ${audioDataSize}bytes, ê¸¸ì´: ${durationSeconds}ì´ˆ")

                            withContext(Dispatchers.Main) {
                                _uiState.value = _uiState.value.copy(
                                    isProcessingSTT = true,
                                    sttDebugInfo = "ì²­í¬ #$chunkCount ì²˜ë¦¬ì¤‘ (${String.format("%.1f", durationSeconds)}ì´ˆ)"
                                )
                            }

                            try {
                                // ì˜¤ë””ì˜¤ ì²­í¬ ê²°í•©
                                val combinedAudio = combineAudioChunks(audioChunks.toList())

                                // WAV íŒŒì¼ ìƒì„±
                                val tempWavFile = createTempWavFile(context, combinedAudio)

                                // ë™ê¸°ì ìœ¼ë¡œ STT ì²˜ë¦¬ (ìˆœì„œ ë³´ì¥)
                                val recognizedText = processSTTChunk(tempWavFile)

                                // í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šê³  "Unit"ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì²˜ë¦¬
                                if (recognizedText.isNotBlank() && !recognizedText.contains("Unit")) {
                                    withContext(Dispatchers.Main) {
                                        val currentState = _uiState.value
                                        val newText = if (currentState.textContent.isEmpty()) {
                                            recognizedText
                                        } else {
                                            "${currentState.textContent} $recognizedText"
                                        }

                                        _uiState.value = currentState.copy(
                                            textContent = newText,
                                            sttError = null,
                                            sttDebugInfo = "ì¸ì‹ ì„±ê³µ: '$recognizedText'"
                                        )

                                        Log.d("GasWritingViewModel", "í…ìŠ¤íŠ¸ ì¸ì‹ ì„±ê³µ: $recognizedText")
                                    }
                                } else if (recognizedText.contains("Unit")) {
                                    Log.w("GasWritingViewModel", "Unitì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ ê°ì§€: $recognizedText")
                                }

                                audioChunks.clear()
                                lastProcessTime = currentTime
                                totalAudioProcessed += audioDataSize

                            } catch (e: Exception) {
                                Log.e("GasWritingViewModel", "ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜", e)
                                withContext(Dispatchers.Main) {
                                    _uiState.value = _uiState.value.copy(
                                        sttError = "ì²˜ë¦¬ ì˜¤ë¥˜: ${e.message}",
                                        sttDebugInfo = "ì²­í¬ #$chunkCount ì²˜ë¦¬ ì‹¤íŒ¨"
                                    )
                                }
                            }

                            withContext(Dispatchers.Main) {
                                _uiState.value = _uiState.value.copy(isProcessingSTT = false)
                            }
                        }
                    }

                    delay(PROCESSING_DELAY_MS)

                } catch (e: Exception) {
                    Log.e("GasWritingViewModel", "ì˜¤ë””ì˜¤ ì½ê¸° ì˜¤ë¥˜", e)
                    withContext(Dispatchers.Main) {
                        _uiState.value = _uiState.value.copy(
                            sttError = "ì˜¤ë””ì˜¤ ì½ê¸° ì˜¤ë¥˜: ${e.message}"
                        )
                    }
                    break
                }
            }

            Log.d("GasWritingViewModel", "ë…¹ìŒ ì¢…ë£Œ - ì´ ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤: ${totalAudioProcessed}bytes, ì²­í¬ ìˆ˜: $chunkCount")
        }
    }

    // VAD (Voice Activity Detection) êµ¬í˜„
    private fun isVoicePresent(audioData: ShortArray): Boolean {
        if (audioData.isEmpty()) return false

        // RMS (Root Mean Square) ê³„ì‚°
        val rms = kotlin.math.sqrt(
            audioData.map { it.toDouble() * it.toDouble() }.average()
        )

        // ìµœëŒ€ ì§„í­ë„ ì²´í¬
        val maxAmplitude = audioData.map { abs(it.toInt()) }.maxOrNull() ?: 0

        val hasVoice = rms > VOICE_THRESHOLD || maxAmplitude > VOICE_THRESHOLD * 3

        if (hasVoice) {
            Log.d("GasWritingViewModel", "ìŒì„± ê°ì§€ - RMS: ${String.format("%.2f", rms)}, ìµœëŒ€ì§„í­: $maxAmplitude")
        }

        return hasVoice
    }

    // ë™ê¸°ì  STT ì²˜ë¦¬ (ê°œì„ )
    private suspend fun processSTTChunk(audioFile: File): String {
        return try {
            val fileSize = audioFile.length()
            Log.d("GasWritingViewModel", "STT ìš”ì²­ - íŒŒì¼í¬ê¸°: ${fileSize}bytes")

            val requestBody = audioFile.readBytes().toRequestBody("application/octet-stream".toMediaTypeOrNull())

            val response = withContext(Dispatchers.IO) {
                clovaSpeechApi.speechToText(
                    clientId = CLIENT_ID,
                    clientSecret = CLIENT_SECRET,
                    language = LANGUAGE,
                    audioData = requestBody
                )
            }

            // ê²°ê³¼ë¥¼ ëª…í™•í•˜ê²Œ Stringìœ¼ë¡œ ì²˜ë¦¬
            val result: String = if (response.isSuccessful) {
                response.body()?.let { speechResponse ->
                    // textê°€ nullì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                    val text = speechResponse.text?.trim() ?: ""
                    Log.d("GasWritingViewModel", "STT ì‘ë‹µ: '$text'")
                    text
                } ?: ""
            } else {
                val errorMessage = when (response.code()) {
                    400 -> "ì˜ëª»ëœ ìš”ì²­ (ì˜¤ë””ì˜¤ í˜•ì‹ í™•ì¸)"
                    401 -> "ì¸ì¦ ì‹¤íŒ¨ (API í‚¤ í™•ì¸)"
                    413 -> "íŒŒì¼ì´ ë„ˆë¬´ í¼"
                    429 -> "API í˜¸ì¶œ í•œë„ ì´ˆê³¼"
                    500 -> "ì„œë²„ ì˜¤ë¥˜"
                    else -> "STT ì˜¤ë¥˜ (${response.code()})"
                }

                Log.e("GasWritingViewModel", "STT ì˜¤ë¥˜: $errorMessage - ${response.errorBody()?.string()}")

                // UI ì—…ë°ì´íŠ¸ëŠ” ë³„ë„ë¡œ ì²˜ë¦¬í•˜ê³  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
                viewModelScope.launch(Dispatchers.Main) {
                    _uiState.value = _uiState.value.copy(
                        sttError = errorMessage,
                        sttDebugInfo = "ì‘ë‹µì½”ë“œ: ${response.code()}"
                    )
                }
                ""
            }

            audioFile.delete()
            result

        } catch (e: Exception) {
            Log.e("GasWritingViewModel", "STT ì²˜ë¦¬ ì‹¤íŒ¨", e)

            // UI ì—…ë°ì´íŠ¸ëŠ” ë³„ë„ë¡œ ì²˜ë¦¬
            viewModelScope.launch(Dispatchers.Main) {
                _uiState.value = _uiState.value.copy(
                    sttError = "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: ${e.message}",
                    sttDebugInfo = "ì˜ˆì™¸: ${e.javaClass.simpleName}"
                )
            }

            audioFile.delete()
            ""
        }
    }

    private fun stopRealTimeSTT() {
        recordingJob?.cancel()
        recordingJob = null

        audioRecord?.apply {
            try {
                if (recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                    stop()
                }
                release()
            } catch (e: Exception) {
                Log.e("GasWritingViewModel", "AudioRecord ì¤‘ì§€ ì˜¤ë¥˜", e)
            }
        }
        audioRecord = null

        _uiState.value = _uiState.value.copy(
            isRecording = false,
            isProcessingSTT = false,
            sttDebugInfo = "ë…¹ìŒ ì¤‘ì§€ë¨"
        )

        Log.d("GasWritingViewModel", "ì‹¤ì‹œê°„ STT ì¤‘ì§€ ì™„ë£Œ")
    }

    // ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ê°œì„ )
    private fun combineAudioChunks(chunks: List<ByteArray>): ByteArray {
        val outputStream = ByteArrayOutputStream()
        chunks.forEach { chunk ->
            outputStream.write(chunk)
        }
        val result = outputStream.toByteArray()
        Log.d("GasWritingViewModel", "ì˜¤ë””ì˜¤ ì²­í¬ ê²°í•© - ì²­í¬ ìˆ˜: ${chunks.size}, ì´ í¬ê¸°: ${result.size}bytes")
        return result
    }

    private fun createTempWavFile(context: Context, audioData: ByteArray): File {
        val timeStamp = SimpleDateFormat("yyyyMMdd_HHmmss_SSS", Locale.getDefault()).format(Date())
        val file = File.createTempFile("realtime_${timeStamp}_", ".wav", context.cacheDir)

        try {
            FileOutputStream(file).use { fos ->
                writeWavHeader(fos, audioData.size)
                fos.write(audioData)
            }
            Log.d("GasWritingViewModel", "WAV íŒŒì¼ ìƒì„± ì™„ë£Œ - ${file.name}, í¬ê¸°: ${file.length()}bytes")
        } catch (e: IOException) {
            Log.e("GasWritingViewModel", "WAV íŒŒì¼ ìƒì„± ì‹¤íŒ¨", e)
            throw e
        }

        return file
    }

    private fun writeWavHeader(fos: FileOutputStream, audioDataSize: Int) {
        val totalDataLen = audioDataSize + 36
        val channels = 1
        val byteRate = sampleRate * channels * 2

        fos.write("RIFF".toByteArray())
        fos.write(intToByteArray(totalDataLen))
        fos.write("WAVE".toByteArray())
        fos.write("fmt ".toByteArray())
        fos.write(intToByteArray(16))
        fos.write(shortToByteArray(1))
        fos.write(shortToByteArray(channels.toShort()))
        fos.write(intToByteArray(sampleRate))
        fos.write(intToByteArray(byteRate))
        fos.write(shortToByteArray((channels * 2).toShort()))
        fos.write(shortToByteArray(16))
        fos.write("data".toByteArray())
        fos.write(intToByteArray(audioDataSize))
    }

    private fun intToByteArray(value: Int): ByteArray {
        return byteArrayOf(
            (value and 0xFF).toByte(),
            ((value shr 8) and 0xFF).toByte(),
            ((value shr 16) and 0xFF).toByte(),
            ((value shr 24) and 0xFF).toByte()
        )
    }

    private fun shortToByteArray(value: Short): ByteArray {
        return byteArrayOf(
            (value.toInt() and 0xFF).toByte(),
            ((value.toInt() shr 8) and 0xFF).toByte()
        )
    }

    fun uploadFeed(context: Context, callback: () -> Unit) {
        val uri = uiState.value.imageUri ?: return
        val text = uiState.value.textContent

        viewModelScope.launch {
            _uiState.value = _uiState.value.copy(isLoading = true)

            try {
                val inputStream = context.contentResolver.openInputStream(uri)
                    ?: throw IOException("Uri InputStream is null")

                val requestFile = inputStream.readBytes()
                    .toRequestBody("image/*".toMediaTypeOrNull())

                val fileName = "image_${System.currentTimeMillis()}.jpg"
                val mediaPart = MultipartBody.Part.createFormData("media", fileName, requestFile)

                val textPart = text.toRequestBody("text/plain".toMediaTypeOrNull())
                val memberIdPart = "2".toRequestBody("text/plain".toMediaTypeOrNull())

                uploadService.postFeed(
                    memberId = memberIdPart,
                    media = mediaPart,
                    text = textPart
                )

                Log.d("Upload", "ì—…ë¡œë“œ ì„±ê³µ")

            } catch (e: Exception) {
                Log.e("Upload", "ì—…ë¡œë“œ ì‹¤íŒ¨", e)
            } finally {
                _uiState.value = _uiState.value.copy(isLoading = false)
                callback()
                showCustomToast(
                    context = context,
                    message = "ì—…ë¡œë“œ ì™„ë£Œ!"
                )
            }
        }
    }

    fun clearError() {
        _uiState.value = _uiState.value.copy(sttError = null, sttDebugInfo = "")
    }

    override fun onCleared() {
        super.onCleared()
        stopRealTimeSTT()
    }
}