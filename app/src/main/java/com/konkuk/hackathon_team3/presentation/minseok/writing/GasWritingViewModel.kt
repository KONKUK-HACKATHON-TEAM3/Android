package com.konkuk.hackathon_team3.presentation.minseok.writing

import android.Manifest
import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.net.Uri
import android.util.Log
import android.widget.Toast
import androidx.annotation.RequiresPermission
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.konkuk.hackathon_team3.data.mapper.toRankingDataList
import com.konkuk.hackathon_team3.data.service.ClovaServicePool
import com.konkuk.hackathon_team3.data.service.ServicePool
import com.konkuk.hackathon_team3.presentation.util.showCustomToast
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.delay
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import okhttp3.Callback
import okhttp3.MediaType.Companion.toMediaTypeOrNull
import okhttp3.MultipartBody
import okhttp3.RequestBody.Companion.asRequestBody
import okhttp3.RequestBody.Companion.toRequestBody
import java.io.ByteArrayOutputStream
import java.io.File
import java.io.FileOutputStream
import java.io.IOException
import java.text.SimpleDateFormat
import java.util.Date
import java.util.Locale

data class GasWritingUiState(
    // ê²Œì‹œë¬¼ ê´€ë ¨
    val imageUri: Uri? = null,
    val textContent: String = "",

    // ì‹¤ì‹œê°„ STT ê´€ë ¨
    val isRecording: Boolean = false,
    val hasAudioPermission: Boolean = false,
    val hasCameraPermission: Boolean = false,
    val isProcessingSTT: Boolean = false,
    val sttError: String? = null,

    val isLoading : Boolean = false
)

class GasWritingViewModel : ViewModel() {
    private val uploadService by lazy { ServicePool.uploadService }


    private val _uiState = MutableStateFlow(GasWritingUiState())
    val uiState: StateFlow<GasWritingUiState> = _uiState.asStateFlow()

    // ğŸ¯ ê³ ì • ê°’ë“¤
    companion object{
        private const val CLIENT_ID = "fsg56x4fn7"
        private const val CLIENT_SECRET = "ng7hVU1DwYZ7CwM2TfjAej8nfmyGzkbq0DX6TpE8"
        private const val LANGUAGE = "Kor"

        private const val CHUNK_DURATION_MS = 600L

        private const val PROCESSING_DELAY_MS = 20L
    }

    // ì‹¤ì‹œê°„ STTìš©ë§Œ ë‚¨ê¹€
    private var audioRecord: AudioRecord? = null
    private var recordingJob: Job? = null

    // ì˜¤ë””ì˜¤ ì„¤ì •
    private val sampleRate = 16000
    private val channelConfig = AudioFormat.CHANNEL_IN_MONO
    private val audioFormat = AudioFormat.ENCODING_PCM_16BIT
    private val bufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat) * 2

    private val clovaSpeechApi = ClovaServicePool.clovaSpeechService

    // ê¶Œí•œ ê´€ë¦¬
    fun updateAudioPermission(hasPermission: Boolean) {
        _uiState.value = _uiState.value.copy(hasAudioPermission = hasPermission)
    }

    fun updateCameraPermission(hasPermission: Boolean) {
        _uiState.value = _uiState.value.copy(hasCameraPermission = hasPermission)
    }

    // ì´ë¯¸ì§€ ì„¤ì •
    fun setImageUri(uri: Uri?) {
        _uiState.value = _uiState.value.copy(imageUri = uri)
    }

    // í…ìŠ¤íŠ¸ ìˆ˜ì • (TextFieldìš©)
    fun updateTextContent(text: String) {
        _uiState.value = _uiState.value.copy(textContent = text)
    }

    fun clearText() {
        _uiState.value = _uiState.value.copy(textContent = "")
    }

    // ğŸ¯ ì‹¤ì‹œê°„ STT í† ê¸€
    @RequiresPermission(Manifest.permission.RECORD_AUDIO)
    fun toggleRecording(context: Context) {
        if (_uiState.value.isRecording) {
            stopRealTimeSTT()
        } else {
            startRealTimeSTT(context)
        }
    }

    @RequiresPermission(Manifest.permission.RECORD_AUDIO)
    private fun startRealTimeSTT(context: Context) {
        if (!_uiState.value.hasAudioPermission) {
            _uiState.value = _uiState.value.copy(sttError = "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤")
            return
        }

        try {
            audioRecord = AudioRecord(
                MediaRecorder.AudioSource.MIC,
                sampleRate,
                channelConfig,
                audioFormat,
                bufferSize
            )

            if (audioRecord?.state == AudioRecord.STATE_INITIALIZED) {
                audioRecord?.startRecording()

                _uiState.value = _uiState.value.copy(
                    isRecording = true,
                    sttError = null
                )

                startRealTimeProcessing(context)
                Log.d("GasWritingViewModel", "ì‹¤ì‹œê°„ STT ì‹œì‘")
            }
        } catch (e: Exception) {
            Log.e("GasWritingViewModel", "ì‹¤ì‹œê°„ STT ì‹œì‘ ì‹¤íŒ¨", e)
            _uiState.value = _uiState.value.copy(
                sttError = "ì‹¤ì‹œê°„ STT ì‹œì‘ ì‹¤íŒ¨: ${e.message}"
            )
        }
    }

    private fun startRealTimeProcessing(context: Context) {
        recordingJob = viewModelScope.launch(Dispatchers.IO) {
            val bufferSizePerChunk = (sampleRate * 2 * CHUNK_DURATION_MS / 1000).toInt()
            val audioBuffer = ShortArray(bufferSizePerChunk / 2)
            val audioChunks = mutableListOf<ByteArray>()

            var lastProcessTime = System.currentTimeMillis()

            while (_uiState.value.isRecording &&
                audioRecord?.recordingState == AudioRecord.RECORDSTATE_RECORDING) {

                try {
                    val bytesRead = audioRecord?.read(audioBuffer, 0, audioBuffer.size) ?: 0

                    if (bytesRead > 0) {
                        val byteArray = ByteArray(bytesRead * 2)
                        for (i in 0 until bytesRead) {
                            val shortValue = audioBuffer[i]
                            byteArray[i * 2] = (shortValue.toInt() and 0xFF).toByte()
                            byteArray[i * 2 + 1] = ((shortValue.toInt() shr 8) and 0xFF).toByte()
                        }
                        audioChunks.add(byteArray)

                        val currentTime = System.currentTimeMillis()
                        if (currentTime - lastProcessTime >= CHUNK_DURATION_MS && audioChunks.isNotEmpty()) {

                            withContext(Dispatchers.Main) {
                                _uiState.value = _uiState.value.copy(isProcessingSTT = true)
                            }

                            try {
                                val combinedAudio = combineAudioChunks(audioChunks.toList())
                                val tempWavFile = createTempWavFile(context, combinedAudio)

                                launch {
                                    processSTTChunk(tempWavFile)
                                }

                                audioChunks.clear()
                                lastProcessTime = currentTime

                            } catch (e: Exception) {
                                Log.e("GasWritingViewModel", "ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜", e)
                            }

                            withContext(Dispatchers.Main) {
                                _uiState.value = _uiState.value.copy(isProcessingSTT = false)
                            }
                        }
                    }

                    delay(PROCESSING_DELAY_MS)

                } catch (e: Exception) {
                    Log.e("GasWritingViewModel", "ì˜¤ë””ì˜¤ ì½ê¸° ì˜¤ë¥˜", e)
                    break
                }
            }
        }
    }

    private suspend fun processSTTChunk(audioFile: File) {
        try {
            val requestBody = audioFile.readBytes().toRequestBody("application/octet-stream".toMediaTypeOrNull())

            val response = withContext(Dispatchers.IO) {
                clovaSpeechApi.speechToText(
                    clientId = CLIENT_ID,
                    clientSecret = CLIENT_SECRET,
                    language = LANGUAGE,
                    audioData = requestBody
                )
            }

            if (response.isSuccessful) {
                response.body()?.let { speechResponse ->
                    val recognizedText = speechResponse.text.trim()

                    if (recognizedText.isNotEmpty()) {
                        withContext(Dispatchers.Main) {
                            val currentState = _uiState.value
                            val newText = if (currentState.textContent.isEmpty()) {
                                recognizedText
                            } else {
                                "${currentState.textContent} $recognizedText"
                            }

                            _uiState.value = currentState.copy(
                                textContent = newText,
                                sttError = null
                            )
                        }
                    }
                }
            } else {
                withContext(Dispatchers.Main) {
                    val errorMessage = when (response.code()) {
                        400 -> "ì˜ëª»ëœ ìš”ì²­"
                        401 -> "ì¸ì¦ ì‹¤íŒ¨"
                        413 -> "íŒŒì¼ì´ ë„ˆë¬´ í¼"
                        429 -> "API í˜¸ì¶œ í•œë„ ì´ˆê³¼"
                        500 -> "ì„œë²„ ì˜¤ë¥˜"
                        else -> "STT ì˜¤ë¥˜"
                    }

                    _uiState.value = _uiState.value.copy(sttError = errorMessage)
                }
            }

            audioFile.delete()

        } catch (e: Exception) {
            withContext(Dispatchers.Main) {
                _uiState.value = _uiState.value.copy(sttError = "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜")
            }
            audioFile.delete()
        }
    }

    private fun stopRealTimeSTT() {
        recordingJob?.cancel()
        recordingJob = null

        audioRecord?.apply {
            try {
                if (recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                    stop()
                }
                release()
            } catch (e: Exception) {
                Log.e("GasWritingViewModel", "AudioRecord ì¤‘ì§€ ì˜¤ë¥˜", e)
            }
        }
        audioRecord = null

        _uiState.value = _uiState.value.copy(
            isRecording = false,
            isProcessingSTT = false
        )
    }

    // ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    private fun combineAudioChunks(chunks: List<ByteArray>): ByteArray {
        val outputStream = ByteArrayOutputStream()
        chunks.forEach { chunk ->
            outputStream.write(chunk)
        }
        return outputStream.toByteArray()
    }

    private fun createTempWavFile(context: Context, audioData: ByteArray): File {
        val timeStamp = SimpleDateFormat("yyyyMMdd_HHmmss_SSS", Locale.getDefault()).format(Date())
        val file = File.createTempFile("realtime_${timeStamp}_", ".wav", context.cacheDir)

        try {
            FileOutputStream(file).use { fos ->
                writeWavHeader(fos, audioData.size)
                fos.write(audioData)
            }
        } catch (e: IOException) {
            Log.e("GasWritingViewModel", "WAV íŒŒì¼ ìƒì„± ì‹¤íŒ¨", e)
        }

        return file
    }

    private fun writeWavHeader(fos: FileOutputStream, audioDataSize: Int) {
        val totalDataLen = audioDataSize + 36
        val channels = 1
        val byteRate = sampleRate * channels * 2

        fos.write("RIFF".toByteArray())
        fos.write(intToByteArray(totalDataLen))
        fos.write("WAVE".toByteArray())
        fos.write("fmt ".toByteArray())
        fos.write(intToByteArray(16))
        fos.write(shortToByteArray(1))
        fos.write(shortToByteArray(channels.toShort()))
        fos.write(intToByteArray(sampleRate))
        fos.write(intToByteArray(byteRate))
        fos.write(shortToByteArray((channels * 2).toShort()))
        fos.write(shortToByteArray(16))
        fos.write("data".toByteArray())
        fos.write(intToByteArray(audioDataSize))
    }

    private fun intToByteArray(value: Int): ByteArray {
        return byteArrayOf(
            (value and 0xFF).toByte(),
            ((value shr 8) and 0xFF).toByte(),
            ((value shr 16) and 0xFF).toByte(),
            ((value shr 24) and 0xFF).toByte()
        )
    }

    private fun shortToByteArray(value: Short): ByteArray {
        return byteArrayOf(
            (value.toInt() and 0xFF).toByte(),
            ((value.toInt() shr 8) and 0xFF).toByte()
        )
    }

    fun uploadFeed(context: Context,callback:()->Unit) {
        val uri = uiState.value.imageUri ?: return
        val text = uiState.value.textContent

        viewModelScope.launch {
            _uiState.value = _uiState.value.copy(isLoading = true)

            try {
                // ğŸ”¥ File ëŒ€ì‹  InputStream ì‚¬ìš©
                val inputStream = context.contentResolver.openInputStream(uri)
                    ?: throw IOException("Uri InputStream is null")

                val requestFile = inputStream.readBytes()
                    .toRequestBody("image/*".toMediaTypeOrNull())

                val fileName = "image_${System.currentTimeMillis()}.jpg"
                val mediaPart = MultipartBody.Part.createFormData("media", fileName, requestFile)

                val textPart = text.toRequestBody("text/plain".toMediaTypeOrNull())
                val memberIdPart = "1".toRequestBody("text/plain".toMediaTypeOrNull())

                uploadService.postFeed(
                    memberId = memberIdPart,
                    media = mediaPart,
                    text = textPart
                )

                Log.d("Upload", "ì—…ë¡œë“œ ì„±ê³µ")

            } catch (e: Exception) {
                Log.e("Upload", "ì—…ë¡œë“œ ì‹¤íŒ¨", e)
            } finally {
                _uiState.value = _uiState.value.copy(isLoading = false)
                callback()
                showCustomToast(
                    context = context,
                    message = "ì—…ë¡œë“œ ì™„ë£Œ!"
                )
            }
        }
    }

    fun clearError() {
        _uiState.value = _uiState.value.copy(sttError = null)
    }

    override fun onCleared() {
        super.onCleared()
        stopRealTimeSTT()
    }
}
